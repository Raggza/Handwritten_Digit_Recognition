{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the image\n",
    "\n",
    "# Normalize the image to [0,1] range\n",
    "X_train = X_train.astype(np.float32)/255\n",
    "X_test = X_test.astype(np.float32)/255\n",
    "\n",
    "# Expand the dimension of images to (28,28,1)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "# Convert classes to one hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), input_shape = (28,28,1), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss= keras.losses.categorical_crossentropy, metrics= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "# EarlyStopping\n",
    "es = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=4, verbose=1)\n",
    "\n",
    "# ModelCheckpoint\n",
    "mc = ModelCheckpoint(\"G://Python//MNIST//MNIST_model.h5\", monitor='val_accuracy', verbose=1, save_best_only= True)\n",
    "\n",
    "cb = [es, mc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1313 [..............................] - ETA: 15s - loss: 0.0016 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 9s 7ms/step - loss: 0.0439 - accuracy: 0.9862 - val_loss: 0.0438 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98656, saving model to G://Python//MNIST//MNIST_model.h5\n",
      "Epoch 2/50\n",
      "1313/1313 [==============================] - 9s 7ms/step - loss: 0.0384 - accuracy: 0.9876 - val_loss: 0.0479 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.98656\n",
      "Epoch 3/50\n",
      "1313/1313 [==============================] - 9s 7ms/step - loss: 0.0326 - accuracy: 0.9897 - val_loss: 0.0433 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.98656 to 0.98761, saving model to G://Python//MNIST//MNIST_model.h5\n",
      "Epoch 4/50\n",
      "1313/1313 [==============================] - 9s 7ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0396 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98761 to 0.98839, saving model to G://Python//MNIST//MNIST_model.h5\n",
      "Epoch 5/50\n",
      "1313/1313 [==============================] - 9s 7ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.0385 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.98839 to 0.98917, saving model to G://Python//MNIST//MNIST_model.h5\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, validation_split= 0.3, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S = keras.models.load_model(\"G://Python//MNIST//MNIST_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9903\n",
      "The model accuracy is 0.9902999997138977\n"
     ]
    }
   ],
   "source": [
    "score = model_S.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"The model accuracy is {score[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
